{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzNxLC_Wz5hK"
      },
      "source": [
        "# Введение в обработку текста на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ99T0N6z5hQ"
      },
      "source": [
        "Материалы:\n",
        "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
        "* https://realpython.com/nltk-nlp-python/\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vRz2Wzsz5hV"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoLjZ_Byz5hb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "f3617340-02cd-4c4e-d3b5-a999e8fbfd19"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-223a39775638>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymorphy2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pymorphy2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0nMWLx2z5hd"
      },
      "source": [
        "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4uoW7f3z5hf"
      },
      "outputs": [],
      "source": [
        "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hiyo65E3z5hh"
      },
      "source": [
        "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MNpUSXbz5hh"
      },
      "source": [
        "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apMjplKbz5hi"
      },
      "source": [
        "## Лабораторная работа 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4IgzSaHz5hk"
      },
      "source": [
        "### Расстояние редактирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wuiArPjz5hl"
      },
      "source": [
        "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXrhFO2o6RkA",
        "outputId": "933b8b1f-89e8-43cf-a41e-a3925e513739"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "recipes = pd.read_csv('recipes_sample.csv').dropna()\n",
        "words=[]\n",
        "for des in recipes['description']:\n",
        "  words+=word_tokenize(des) \n",
        "words=list(set(words))\n",
        "\n",
        "print(words[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ffhHbg3GiY",
        "outputId": "93fa02fe-742d-4d51-a87d-5f846c53be22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['8.5', 'friendly', 'create', 'party/gathering', 'best/traditionally']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X16LzwH8z5hm"
      },
      "source": [
        "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics.distance import *\n",
        "import random"
      ],
      "metadata": {
        "id": "v2aFsuhuz7Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listt = ['inferno','magnesium','ufo','dark','moon']\n",
        "for i in range(5):\n",
        "  w1,w2 = random.sample(listt,2)\n",
        "  dist = edit_distance(w1,w2)\n",
        "  print(f\"Distance between '{w1}' and '{w2}' = '{dist}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai-zM10F0gng",
        "outputId": "f6c15453-af5d-4cf8-a6fd-b1152c952eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between 'inferno' and 'ufo' = '5'\n",
            "Distance between 'magnesium' and 'inferno' = '8'\n",
            "Distance between 'dark' and 'moon' = '4'\n",
            "Distance between 'dark' and 'inferno' = '6'\n",
            "Distance between 'inferno' and 'ufo' = '5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ibaZKvz5hm"
      },
      "source": [
        "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_old(word):\n",
        "  words = ['inferno','magnesium','ufo','dark','moon','thelema']\n",
        "  for j in words:\n",
        "       dist = int(edit_distance(word,j))\n",
        "       print(f\"Distance between '{word}' and '{j}' = '{dist}'\")"
      ],
      "metadata": {
        "id": "jS30bH-p2BXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(word,k):\n",
        "  words = ['inferno','magnesium','ufo','dark','moon','thelema']\n",
        "  dist = {j:edit_distance(word,j) for j in words}\n",
        "  res = sorted(dist,key = dist.get)[:k]\n",
        "  return res"
      ],
      "metadata": {
        "id": "BIep14Ix-vF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search('tramendous',3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKHYxSoT22NF",
        "outputId": "b4e1ed46-4b94-4b67-e44b-a7ac15ac5031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['inferno', 'magnesium', 'moon']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IW0mJ5dz5hm"
      },
      "source": [
        "### Стемминг, лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-mj_yiFz5hn"
      },
      "source": [
        "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
        "    * word\n",
        "    * stemmed_word \n",
        "    * normalized_word \n",
        "\n",
        "Столбец `word` укажите в качестве индекса. \n",
        "\n",
        "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import *\n",
        "import pandas as pd\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T1dFaJGBRFL",
        "outputId": "19ad5848-3dab-4fe5-b1e9-4904256762b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "recipes = pd.read_csv('recipes_sample.csv').dropna()\n",
        "words=[]\n",
        "for des in recipes['description']:\n",
        "  words+=word_tokenize(des) \n",
        "words=list(set(words))\n",
        "\n",
        "#print(words)\n",
        "\n",
        "stemma = SnowballStemmer('english')\n",
        "lemma = WordNetLemmatizer()\n",
        "#words = ['inferno','magnesium','cats','darkness','moons','thelema']\n",
        "df = pd.DataFrame(index = [word for word in words],columns=['word','stemmed_word','normalized_word'])\n",
        "for word in words:\n",
        "  df.at[word,'word'] = word\n",
        "  df.at[word,'stemmed_word'] = stemma.stem(word)\n",
        "  df.at[word,'normalized_word'] = lemma.lemmatize(word)\n",
        "\n",
        "print(df[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iv1dJ5IBQoa",
        "outputId": "2121f0d6-c11a-4d7d-cdb4-04337a48e091"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  word stemmed_word     normalized_word\n",
            "8.5                                8.5          8.5                 8.5\n",
            "friendly                      friendly       friend            friendly\n",
            "create                          create        creat              create\n",
            "party/gathering        party/gathering   party/gath     party/gathering\n",
            "best/traditionally  best/traditionally  best/tradit  best/traditionally\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemma = SnowballStemmer('english')\n",
        "lemma = WordNetLemmatizer()\n",
        "words = ['inferno','magnesium','cats','darkness','moons','thelema']\n",
        "df = pd.DataFrame(index = [word for word in words],columns=['word','stemmed_word','normalized_word'])\n",
        "for word in words:\n",
        "  df.at[word,'word'] = word\n",
        "  df.at[word,'stemmed_word'] = stemma.stem(word)\n",
        "  df.at[word,'normalized_word'] = lemma.lemmatize(word)\n",
        "\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmhyvXLGAqlk",
        "outputId": "b0acef3d-e01a-4944-8c16-d5d2e139daad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                word stemmed_word normalized_word\n",
            "inferno      inferno      inferno         inferno\n",
            "magnesium  magnesium    magnesium       magnesium\n",
            "cats            cats          cat             cat\n",
            "darkness    darkness         dark        darkness\n",
            "moons          moons         moon            moon\n",
            "thelema      thelema      thelema         thelema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BonNiLz8z5ho"
      },
      "source": [
        "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "nZTNIwSGUPU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipes = pd.read_csv('recipes_sample.csv')\n",
        "recipe_c = recipes.copy()\n",
        "recipe_c = recipe_c.astype({'description':str})\n",
        "new = recipe_c['description'].tolist()\n",
        "for i in range(0,len(new)):\n",
        "  re.sub('\\d', ' ',new[i])"
      ],
      "metadata": {
        "id": "blg-U1N0Rjwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbu6irIHT55",
        "outputId": "2a91d93d-7f69-4f93-8e84-e8ad96ddf4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = list(set(stopwords.words('english')))\n",
        "tok = word_tokenize(new.lower())\n",
        "tok_wto_stopw=[word for word in tok if word not in stop_words]\n",
        "tok_wto_stopw"
      ],
      "metadata": {
        "id": "4oayfbH4abQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = list(set(stopwords.words('english')))\n",
        "\n",
        "filtered_words = [new[i] for i in range(len(new)) if new[i].lower() not in stop_words]\n",
        "top10_before = pd.Series(new).value_counts().head(10)\n",
        "top10_after = pd.Series(filtered_words).value_counts().head(10)\n",
        "\n",
        "stop_wr_count = len([i for i in new if i.lower() in stop_words])\n",
        "total_wr_count = len(new)\n",
        "stop_ratio = stop_wr_count / total_wr_count\n",
        "\n",
        "print('Stop_words_count',stop_wr_count)\n",
        "print('total_wr_count', total_wr_count)\n",
        "print('stop_wr_count',stop_wr_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyMRzvFRJfVS",
        "outputId": "09552b38-9197-416f-9a28-0e663aac328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop_words_count 0\n",
            "total_wr_count 30000\n",
            "stop_wr_count 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ5OvWrvz5hp"
      },
      "source": [
        "### Векторное представление текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeTCCIOmz5hq"
      },
      "source": [
        "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`(важность использования каждого слова из некоторого набора слов (количество слов набора определяет размерность вектора))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "recipes = pd.read_csv('recipes_sample.csv')\n",
        "random_recs = recipes.sample(n=5)\n",
        "\n",
        "vectorz = TfidfVectorizer(stop_words = 'english')\n",
        "vectors = vectorz.fit_transform(random_recs['description'])\n",
        "\n",
        "k = 0 \n",
        "for i,rec in random_recs.iterrows():\n",
        "  print(f\"Recipe {i+1}:{rec['name']}\")\n",
        "  print(f\"Vector description : {vectors[k].toarray()}\")\n",
        "  k+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLxs8S8pwSqn",
        "outputId": "60b145f8-8919-4d0c-b161-438f5ef2eb02"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe 12124:gluten free   like campbells   tomato soup\n",
            "Vector description : [[0.         0.         0.20851441 0.20851441 0.20851441 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.20851441 0.         0.         0.20851441\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.20851441 0.         0.         0.20851441 0.\n",
            "  0.         0.         0.         0.         0.20851441 0.\n",
            "  0.         0.20851441 0.         0.         0.62554324 0.\n",
            "  0.         0.         0.         0.         0.41702883 0.\n",
            "  0.20851441 0.         0.         0.        ]]\n",
            "Recipe 13595:hellman s grilled asian kabobs appetizer  shrimp\n",
            "Vector description : [[0.26726124 0.26726124 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.26726124 0.         0.26726124 0.26726124 0.         0.\n",
            "  0.         0.         0.26726124 0.26726124 0.         0.26726124\n",
            "  0.         0.26726124 0.         0.         0.         0.26726124\n",
            "  0.26726124 0.         0.         0.         0.         0.26726124\n",
            "  0.         0.         0.         0.26726124 0.         0.26726124\n",
            "  0.         0.         0.         0.        ]]\n",
            "Recipe 10110:easy mushroom rice\n",
            "Vector description : [[0.         0.         0.         0.         0.         0.21821789\n",
            "  0.         0.         0.         0.         0.21821789 0.21821789\n",
            "  0.43643578 0.         0.         0.         0.21821789 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.43643578 0.         0.21821789 0.21821789 0.         0.\n",
            "  0.         0.         0.         0.21821789 0.         0.\n",
            "  0.         0.         0.21821789 0.         0.         0.\n",
            "  0.         0.43643578 0.21821789 0.        ]]\n",
            "Recipe 28912:virgin apple snow cocktail\n",
            "Vector description : [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.35355339 0.35355339 0.         0.\n",
            "  0.         0.35355339 0.         0.         0.         0.\n",
            "  0.         0.35355339 0.         0.         0.35355339 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.35355339 0.         0.         0.\n",
            "  0.35355339 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.35355339]]\n",
            "Recipe 18320:mushroom roll ups\n",
            "Vector description : [[0.         0.         0.         0.         0.         0.\n",
            "  0.40824829 0.40824829 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40824829 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.40824829\n",
            "  0.40824829 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.40824829 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_VOaze0z5hq"
      },
      "source": [
        "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "zBnSfcgCJXv3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(vectors.shape[0]): \n",
        "  print(vectors[i].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KvaTTc5TIza",
        "outputId": "92005ebf-0cf6-439f-dfd3-92f94ad9a4fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.20851441 0.20851441 0.20851441 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.20851441 0.         0.         0.20851441\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.20851441 0.         0.         0.20851441 0.\n",
            "  0.         0.         0.         0.         0.20851441 0.\n",
            "  0.         0.20851441 0.         0.         0.62554324 0.\n",
            "  0.         0.         0.         0.         0.41702883 0.\n",
            "  0.20851441 0.         0.         0.        ]]\n",
            "[[0.26726124 0.26726124 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.26726124 0.         0.26726124 0.26726124 0.         0.\n",
            "  0.         0.         0.26726124 0.26726124 0.         0.26726124\n",
            "  0.         0.26726124 0.         0.         0.         0.26726124\n",
            "  0.26726124 0.         0.         0.         0.         0.26726124\n",
            "  0.         0.         0.         0.26726124 0.         0.26726124\n",
            "  0.         0.         0.         0.        ]]\n",
            "[[0.         0.         0.         0.         0.         0.21821789\n",
            "  0.         0.         0.         0.         0.21821789 0.21821789\n",
            "  0.43643578 0.         0.         0.         0.21821789 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.43643578 0.         0.21821789 0.21821789 0.         0.\n",
            "  0.         0.         0.         0.21821789 0.         0.\n",
            "  0.         0.         0.21821789 0.         0.         0.\n",
            "  0.         0.43643578 0.21821789 0.        ]]\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.35355339 0.35355339 0.         0.\n",
            "  0.         0.35355339 0.         0.         0.         0.\n",
            "  0.         0.35355339 0.         0.         0.35355339 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.35355339 0.         0.         0.\n",
            "  0.35355339 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.35355339]]\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.40824829 0.40824829 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40824829 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.40824829\n",
            "  0.40824829 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.40824829 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "xnJXim_GT_Xz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _validate_vector(u, dtype=None):\n",
        "    # XXX Is order='c' really necessary?\n",
        "    u = np.asarray(u, dtype=dtype, order='c')\n",
        "    if u.ndim == 1:\n",
        "        return u\n",
        "    raise ValueError(\"Input vector should be 1-D.\")"
      ],
      "metadata": {
        "id": "OM_TC6crT55j"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors[0].toarray().ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cakE4qSMUH7U",
        "outputId": "4ff6050d-dd4a-4234-c81d-57367491050b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "si = [] \n",
        "for i in range(vectors.shape[0]): \n",
        "  row = []\n",
        "  for j in range(vectors.shape[0]):\n",
        "    sim= 1 - distance.cosine(vectors[i].toarray().ravel(), vectors[j].toarray().ravel())   #ravel()-to change the dimension of vector to 1-D\n",
        "    row.append(sim) \n",
        "  si.append(row) \n",
        "s_df = pd.DataFrame(si, columns=random_recs['description']) \n",
        "print(s_df)"
      ],
      "metadata": {
        "id": "f5H9of2RYEHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c731e245-291e-4e44-ccec-219e60754d2a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "description  this recipe is as easy as opening a can of commercial tomato soup! the flavour is the about the same and everyone loves it! it can be used just as soup or in casseroles calling for tomato soup.  \\\n",
            "0                                                          1.0                                                                                                                                                   \n",
            "1                                                          0.0                                                                                                                                                   \n",
            "2                                                          0.0                                                                                                                                                   \n",
            "3                                                          0.0                                                                                                                                                   \n",
            "4                                                          0.0                                                                                                                                                   \n",
            "\n",
            "description  from an ad in a magazine.  hellman's is a mayonnaise for those of you outside the united states (it is also know as best food's i think).  the photo looks great.  \\\n",
            "0                                                          0.0                                                                                                                   \n",
            "1                                                          1.0                                                                                                                   \n",
            "2                                                          0.0                                                                                                                   \n",
            "3                                                          0.0                                                                                                                   \n",
            "4                                                          0.0                                                                                                                   \n",
            "\n",
            "description  i usually make this rice for thanksgiving, especially if i have vegetarians at the meal.  it doesn't make much, so double it for company.  i usually don't double the onion.  \\\n",
            "0                                                          0.0                                                                                                                              \n",
            "1                                                          0.0                                                                                                                              \n",
            "2                                                          1.0                                                                                                                              \n",
            "3                                                          0.0                                                                                                                              \n",
            "4                                                          0.0                                                                                                                              \n",
            "\n",
            "description  a refreshing and frosty drink that will help cool you off on those warm summer days.  \\\n",
            "0                                                          0.0                                      \n",
            "1                                                          0.0                                      \n",
            "2                                                          0.0                                      \n",
            "3                                                          1.0                                      \n",
            "4                                                          0.0                                      \n",
            "\n",
            "description  from the 5 ingredients or less cookbook compiled by home economics teachers.  \n",
            "0                                                          0.0                             \n",
            "1                                                          0.0                             \n",
            "2                                                          0.0                             \n",
            "3                                                          0.0                             \n",
            "4                                                          1.0                             \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}